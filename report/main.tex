\documentclass[10pt,a4paper,final,twocolumn]{article}
%\usepackage{fontspec}
%\defaultfontfeatures{Mapping=tex-text}
%\usepackage{xunicode}
%\usepackage{xltxtra}
%\setmainfont{???}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}

\author{Joe Fennell}
\title{High-level simulation of future multispectral imagery from the proposed TreeView satellite. v1.2}

\begin{document}
\maketitle
\begin{abstract}
This document describes the early work carried out for the development of a simulation-evaluation pipeline for earth orbit multispectral imagery. A description of the pipeline is presented and example outputs.
\end{abstract}
\section{Introduction}
% From proposal Docs
The TreeView project proposes a novel satellite solution for climate action that will drive a revolution in ‘Precision Forestry’ –- the use of advanced technologies for a more granular data capture and management. Forests are often considered large, remote areas that require low maintenance during their lifetime and can be managed in homogeneous units called forest stands. But new political, environmental, social and commercial drivers necessitate a more diverse approach of mixed species and smaller scale planting. Individual trees are the fundamental unit of these resources, and the target of TreeView. 

\subsection{Work Package 2000: Science Requirements}
Current work (Q4 2020) focuses on the need to constrain the engineering design with understanding of the likely measurements that will be made with the proposed system. In order to do this, both a simulation methodology and a set of relevant performance metrics must be adopted, such that different combinations of band-pass filter and sensor characteristics can be evaluated for different geographically-relevant atmospheric conditions.

In designing the work the following considerations were made:

\begin{enumerate}
\item As this project relates specifically to the measurement of single trees (as opposed to forest stands), tree stands and individual isolated trees of various sizes will both be considered when designing performance metric experiments
\item Due to the limited knowledge of the likely system architectures at this stage in the development process, a high-level approach will be taken to simulation of synthetic images with assumptions made about the likely distributions and properties of noise at different stages in the simulation.
\item The range of possible spectral sensitivities will be limited to what is feasible with a silicon detector, and observable through standard glass optics ($\lambda \approx 400 - 900$ nm).
\item The simulation pipeline is designed using Dask/Python as it is (i) Open Source (and so easily verified, reviewed and tested by any research group) and (ii) a natively parallel environment for efficient, scalable computation.
\end{enumerate}
 
\subsection{Simulation of a line-scanning sensor}
A line-scanning Time Delay Integration (TDI) Charged Metal Oxide Silicon (CMOS) sensor is the only likely sensor suitable for purpose and so this work focuses on the simulation only of this class of sensor.

\section{Stages of Simulation}
This section details the tools and methodologies used for each stage in the simulation/evaluation pipeline.
\subsection{Imagery Collection}
Hyperspectral aerial imagery from the project partners 2ExcelGeo have been used as the main reference data for these simulations. The relevant datasets from the aerial collect were the HySpex VNIR covering a spectral range covering the 400-900 nm band and at a ground sampling distance of $0.33 m pixel^{-1}$ - much higher spatial and spectral resolution than the proposed mission. Imagery have been collected over a number of UK cities including Milton Keynes and Birmingham. Time sequences (multiple images of the same ground area) have been collected over some areas and will be made available to this team within the current project.

The measured at-sensor radiance is converted to a reflectance value through an  atmospheric correction model implemented in ENVI software (QUAC [ref needed]). This is carried out by the data providers (2ExcelGeo). The QUAC method is based on the use of lookup tables of pure endmember reflectances and their corresponding radiance under known solar conditions. The ill-posed problem is then treated as a spectral-unmixing of known endmembers. It is favoured for it's low computation demand, however there is some concern that the approach may introduce spectral artefacts to the imagery that are hard to quantify and studies have shown worse performance than conventional radiative transfer model inversion methods such as FLAASH [citation needed]. More work needed to understand if a more rigorous atmospheric approach is needed for these data.

\subsection{Atmospheric Simulation}
\subsubsection{Reflectance to at-sensor radiance}
In broad terms, the purpose of the atmospheric simulation is to map from ground reflectance ($\rho$) to an at-sensor radiance ($L_{e, \Omega}$):

\begin{equation}
\rho(\lambda) \rightarrow L_{e, \Omega} (\lambda)
\end{equation}

Established radiative transfer modelling approaches were used in the simulation. Primarily, the 6SV [ref needed] code from NASA was used to convert the measured ground reflectance to at-sensor radiance outside the atmosphere. The code is considered a medium-complexity, line-by-line approach and is used for atmospheric correction of MODIS data. For practical implementation reasons, the 6SV code (a FORTRAN library accessed via the Py6S bindings) has been used to generate Lookup Tables (LUTs) for a limited range of parameter values.

In the first stages, the following approximations are proposed:
\begin{enumerate}
\item The satellite observes each pixel in space, at nadir. If the centre of the image plane is assumed to be directly beneath the satellite's orbital path, then the inaccuracy introduced by this approximation increases towards the edges of the image plane. This is a reasonable approximation for a narrow field-of-view, high resolution device as proposed. 
\item The atmospheric optical thickness will be set at a range typical of the UK. All test data is of UK locations and the UK's climatic conditions are quite challenging for optical imaging. This is therefore a useful starting point for simulation.
\item All individual pixels in the imagery array will be considered as independent homogeneous lambertian diffusers for the purpose of the 6SV simulation. As such, the spatial response function is handled at a later stage in the pipeline.
\item The simulation is evaluated for all wavelengths between 
\end{enumerate}

\subsection{Satellite Geometric Simulation}
The at-satellite radiance ($L_{e,\Omega}(\lambda)$) is in units of power per steradian per ground area ($W sr^{-1} m^{-2}$) and so requires conversion to at-satellite irradiance ($W m^{-2}$). When treated as a thin lens problem (in the absence of optic specifics) the irradiance at a position($\textbf{x}$) on the sensor is calculated as the solid angle subtended by the lens. We follow the interpretation by \cite{Sato1999} to show that sensor irradiance is linearly related to radiance and dependent on the diameter of the front optic ($D$), focal length ($f$) and the pixel-lens normal offset angle ($\alpha$):
\begin{equation}
E_e(\lambda, \textbf{x}) = L_{e,\Omega}(\lambda) \frac{\pi}{4} \left(\frac{D}{f}\right)^{2} \cos^4 \alpha(\textbf{x})
\label{eqn1}
\end{equation}

The angular field of view ($afov$) is calculated from the swath width ($d_{swath}$) and sensor altitude ($d_{altitude}$):

\begin{equation}
afov = 2\cdot \tan^{-1}\frac{0.5\cdot~d_{swath}}{d_{altitude}}
\end{equation}

The focal length ($f$) is calculated assuming the optic will be focused near infinity and so, from the thin lens equation, the distance between rear optic and lens ($s\prime$) is approximately equal:

\begin{equation}
\frac{1}{s\prime} + \frac{1}{\infty} = \frac{1}{f} \approx \frac{1}{s\prime}
\end{equation}

and so by simple trigonometry, the angular field of view ($afov$) and sensor width ($d_{sensor}$) are used to calculate the desired focal length:

\begin{equation}
f= \frac{d_{sensor}}{\tan afov}
\end{equation}

As focal length is expected to be very large due to the distance from target and narrow swath needed to achieve desired ground sampling distances, the $\cos^4\alpha(\textbf{x})$ term will have a minimal effect on the simulation and so is omitted for computational simplicity

\subsection{Sensor Simulation}
The stages of the sensor simulation are given below. Only linear responses (with the exception of physically-motivated truncations) have been modelled here to represent the linear response component of the sensor. Fixed pattern noise has not been modelled.

\subsubsection{Sensor radiance to photon flux}
Initially, pixels in the input array are treated independently and the following stages are carried out element-wise with every pixel treated as a 1D spectrum. The at-sensor irradiance is converted to at-sensor photon rate ($\Phi_{0}(\lambda) $) using the Planck-Einstein relation:
\begin{equation}
\Phi_{0}(\lambda) = E_e(\lambda)\frac{\lambda}{hc}
\end{equation}


\subsubsection{Application of bandpass response functions}
For every band, the bandpass transmittance is multiplied element-wise by the flux and integrated w.r.t. wavelength
\begin{equation}
\Phi_{band}= \int_{400}^{900}(\Phi_0(\lambda)T_i(\lambda))~d\lambda
\end{equation}

where $T_i$ is the transmission spectrum of the $i$th bandpass filter. This provides the per-band photon flux.

\subsubsection{Spatial Resampling}
The spatial response function takes into account atmospheric blurring, optical imperfections, motion blur, etc. of the entire system.

To convert from the ground plane to image plane, the integrated fluxes for each band (${\Phi}_{band}$) are separately convolved with the spatial response function, $g(x,y)$.
\begin{equation}
{\Phi}_{band}(x, y) = g(x, y) * \Phi_{band}(x, y)
\end{equation}
where $x, y$ are ground position indices.

In the absence of more information about the optical properties, the spatial response function ($g(x,y)$) has been approximated as a 2D gaussian with parameters derived empirically. An example of this using the Sentinel 2 Point Spread Function estimated the 10m ground sampling distance Sentinel 2 bands to have a Full Width at Half Maximum (FWHM) of 22.08 m and this ratio was used for preliminary estimates of different ground sampling distances.

The FWHM can be converted to sigma:

\begin{equation}
\sigma_{xy} = \frac{(FWHM/2.355)}{dx}
\end{equation}

where $dx = dy$

and used to generate the gaussian kernel:

\begin{equation}
g(x) =\exp \left(-\left({\frac {(x-x_{o})^{2}}{2\sigma _{xy}^{2}}}+{\frac {(y-y_{o})^{2}}{2\sigma _{xy}^{2}}}\right)\right)
\end{equation}

After convolution, the new array is then resampled by taking the local mean over a subset of cells representing the area of one sensor pixel.

\subsubsection{Pixel photon count}
To convert from pixel flux to pixel photon count:

\begin{equation}
\bar{I_0} =  \Phi_{band} t A
\end{equation}

where $t$ is integration time and $A$ is the area of the pixel. The quantity $\bar{I_0}$  describes the mean number of photons hitting a pixel in any given integration cycle.

\subsubsection{Photon noise}
The photon count at the sensor can be expressed as a Poisson process such that the $\Lambda$ coefficient of each process is the observed count for a given pixel

\begin{equation}
I_0(x, y, band) \sim Poisson(\Lambda)
\end{equation}

Where the estimated photon quantity at each pixel, ${I_0}(x, y, band)$ is the $\Lambda$ coefficient for each distribution.

\subsubsection{Photon to electron}
To convert from photon to electron, given a known sensor quantum efficiency:

\begin{equation}
I_1 =  round(I_0 \cdot \bar{Q}_{E,i})
\end{equation}

where $\bar{Q}_{E,i}$ is the weighted mean of the quantum efficiency in the $i$th channel:

\begin{equation}
\bar{Q}_{E, i} = \sum_{\lambda=300}^{900} Q_{E}(\lambda) \left(\frac{T_i(\lambda)}{\int_{300}^{700} T_i(\lambda) d\lambda}\right)
\end{equation}



\subsubsection{Dark Current Noise}
The contribution of dark current electrons is assumed to be a additive gaussian with zero mean and standard deviation:

\begin{equation}
I_{dark}\sim N(0, \sigma)
\end{equation}

\subsubsection{Conversion to Voltage}
The signals are added and truncated at the full well capacity of the sensor

\begin{equation}
I_2 = trunc(I_1+I_{dark}, C)
\end{equation}
where $C$ is the sensor specific well capacity.

The charge collected during an integration cycle is then converted to a voltage

\begin{equation}
V_s = V_{SN} - I_2 \cdot G_{SN}
\end{equation}
where $V_{SN}$  is the reference voltage (V) and $G_{SN}$ is the sense node gain ($V/e^{-}$).

\subsubsection{Conversion to Digital Number}
The amplified voltage can then be converted to a digital number (DN).

\begin{equation}
DN = trunc(V_{ADC} -V_s \cdot G_{ADC}, DN_{max})
\end{equation}
where $V_{ADC}$  is the Analogue-Digital Converter reference voltage and $G_{ADC}$ is the ADC gain ($DN/V$).

The result is truncated at the maximum DN value ($DN_{max}$) and zero to simulate clipping and non-detection behaviours.

\subsubsection{Conversion to reflectance}
For testing and evaluation purposes, the pipeline is used to generate a sensor response for a 100\% reference image (i.e. all atmospheric and sensor parameters are known \textit{a priori}). The image signal is then divided by reference signal to produce the estimate of reflectance at surface level.

\begin{equation}
\rho = \frac{DN}{DN_{100}}
\end{equation}

Noisy reference spectra can easily be generated by replacing fixed parameters with a distribution from which instances are sampled, for example to explore effect of uncertainties in Atmospheric Optical Thickness (AOT) measurement.


\section{Evaluating Performance}
Performance metrics for a given sensor-atmosphere parametrisation can be divided into classification and parameter estimation metrics.

\subsection{Classification}
No development

\subsection{Parameter estimation}
A spectral index (defined by narrowband wavelength or wavelength ranges) is first estimated from the hyperspectral data and is used as the reference value. An analagous definition for the sensor is then separately defined.

For example for Normalised Difference Vegetation Index (NDVI):

\begin{equation}
S = \frac{\rho_{IR} - \rho_{R}}{\rho_{IR} + \rho_{R}}
\end{equation}

where $\rho$ can be defined differently for each sensor.

As a calibration experiment would normally be carried out to account for the different definitions of $\rho$ between sensors, this can be simulated by fitting a linear regression model between predicted and observed values:

\begin{equation}
S_{sim} = \beta_{0} S_{ref} + \beta_1
\end{equation}

where $\beta_0$ and $\beta_1$ are free parameters.

As the models simulate complex noise distributions and the number of observations is high, a robust regression algorithm is adopted (Random Sample Consensus - RanSaC) to exclude outlying values.

Prior to model fitting, the (assumed lower) resolution simulation is resampled to the same spatial resolution as the reference using nearest-neighbour resampling.

The model is then fitted as described in [RANSAC ref Needed] and raw and calibrated Root Mean Squared Errors (RMSEs) are calculated:

\begin{equation}
RMSE = \sqrt{\frac{(S_{ref}-S_{sim})^{2}}{N}}
\end{equation}

\section{Sample Results}
\subsection{Image Generation}
The pipeline was used to generate test signals for a low noise (10 $e^- pixel ^{-1}$, low spatial resolution (4m Ground Sample Distance) scenario (Figure \ref{fig:1}) and  a high noise (120 $e^- pixel ^{-1}$, low spatial resolution (1m Ground Sample Distance) scenario (Figure \ref{fig:2}). Radiances for a satellite position perpendicular to the centre of the sample imagery (52.04N, 0.76E) on the day the imagery were collected (22/6/2020) at solar noon (12.00 UST) and with a standard coastal atmospheric optical profile were generated for estimating at-sensor radiances.

\begin{figure*}
%\includegraphics[width=\textwidth]{figures/test_output_im1}
\caption{Sample simulated signals (4m GSD, dark noise=10) using a pipeline based on Sentinel-2 VNIR bands and a CCD sensor. The input hyperspectral (A), simulated RGB (B), Predicted false colour NIR (C), Normalised Difference Vegetation Index (D) are shown as images and example input reflectance spectra (E) and example simulated reflectance spectra (F) are shown as line plots. }
\label{fig:1}
\end{figure*}

\begin{figure*}
%\includegraphics[width=\textwidth]{figures/test_output_im2}
\caption{Sample simulated signals (1m GSD, dark noise=120) using a pipeline based on Sentinel-2 VNIR bands and a CCD sensor. The input hyperspectral (A), simulated RGB (B), Predicted false colour NIR (C), Normalised Difference Vegetation Index (D) are shown as images and example input reflectance spectra (E) and example simulated reflectance spectra (F) are shown as line plots. }
\label{fig:2}
\end{figure*}

\begin{table*}
\caption{Processing steps (4m GSD, dark noise=10) using a pipeline based on Sentinel-2 VNIR bands and a CCD sensor corresponding to outputs in Figure \ref{fig:1} }
\small
\include{tables/im1}
\label{tab:params1}
\end{table*}

\begin{table*}
\caption{Processing steps (1m GSD, dark noise=120) using a pipeline based on Sentinel-2 VNIR bands and a CCD sensor corresponding to outputs in Figure \ref{fig:2} }
\small
\include{tables/im2}
\label{tab:params2}
\end{table*}

\begin{table*}
\caption{Processing steps (1m GSD, dark noise=120) using a pipeline based on Sentinel-2 VNIR bands and a CCD sensor corresponding to outputs in Figure \ref{fig:2} }
\small
\begin{tabular}{llll}
\toprule
 & \bf{Stage} & \bf{Function} & \bf{Parameters} \\
\midrule
1 & radiant energy to radiant flux & pyeosim.\_sensor.energy\_to\_quantity & None\\
\midrule
2 & apply bandpass filters & pyeosim.spectral.TreeView\_1 & None\\
\midrule
3 & apply spatial resampling & pyeosim.spatial.gaussian\_isotropic & psf\_fwhm = 4.00\\
 & & & ground\_sample\_distance = 2.00\\
\midrule
4 & radiant flux to flux density & pyeosim.\_sensor.radiance\_to\_irradiance\_2 & lens\_diameter = 0.10\\
 & & & focal\_length = 2.57\\
\midrule
5 & flux density to flux & pyeosim.\_sensor.photon\_mean & pixel\_area = 100.00\\
 & & & integration\_time = 9.14e-03\\
\midrule
6 & add photon shot noise & pyeosim.\_sensor.add\_photon\_noise & None\\
\midrule
7 & photon to electron & pyeosim.\_sensor.photon\_to\_electron & Q\_E = [0.86, ...]\\
\midrule
8 & add photo response non-uniformity & pyeosim.\_sensor.add\_prnu & prnu = [-0.00, ...]\\
\midrule
9 & add dark signal & pyeosim.\_sensor.add\_dark\_signal & dark\_current = 1.82e+04\\
 & & & integration\_time = 9.14e-03\\
 & & & dsnu = [0.00, ...]\\
\midrule
10 & electron to voltage & pyeosim.\_sensor.electron\_to\_voltage\_ktc & v\_ref = 3.10\\
 & & & sense\_node\_gain = 5.00e-06\\
 & & & full\_well = 3.00e+04\\
 & & & temperature = 2.93e+02\\
\midrule
11 & add column offset noise & pyeosim.\_sensor.add\_column\_offset & offset = [-0.00, ...]\\
\midrule
12 & voltage to DN & pyeosim.\_sensor.voltage\_to\_DN & v\_ref = 3.10\\
 & & & adc\_gain = 1.00e+05\\
 & & & bit\_depth = 12.00\\
\midrule
\bottomrule
\end{tabular}

\label{tab:params2}
\end{table*}

\subsection{Demonstration 1: Effect of Dark Noise level}
\begin{figure*}
\centering
%\includegraphics[width=0.5\textwidth]{figures/test_output_dn}
\caption{Uncalibrated (red) and calibrated (black) Root Mean Squared Error for low spatial resolution (solid) and high spatial resolution (dashed) scenarios over a range of dark noise levels}
\label{fig:scores}
\end{figure*}

A simple experiment is presented here, demonstrating how the pipeline can be used to score different sensor properties. In this experiment, the dark noise level ($\sigma_{dark}$) was varied between 0 and 120 electrons per pixel for the scenarios presented in Tables \ref{tab:params1} and \ref{tab:params2}. The scoring metric used was the Root Mean Squared Error (RMSE) of the Normalised Difference Vegetation Index (NDVI).  Each parameter combination was run 10 times (Figure \ref{fig:scores}).

\subsubsection{Performance}
The model, for a 32,400 pixel input image was run 240 times (2 scenarios, 10 repeats, 12 parameter combinations) taking approximately 52 seconds on a 4-core 2.3GHz i5 macbook. Speed increases are likely to be possible once the expected range of parameters to be evaluated are known. Currently the image simulation stage is optimised for parallel use, however the evaluation pipeline needs to be updated to make fully parallel.

\subsubsection{Calibration}
Use of RanSaC calibration decreased the RMSE for both scenarios (Figure \ref{fig:scores}). The lowest RMSE appeared to be at the extreme NDVI values (Figure \ref{fig:cal}). This is expected as the mid-value NDVI values would be generated where the spatial downsampling includes a mixture of extreme values (e.g. the edge between a building and vegetation). The calibration could be improved by fitting piece-wise regression models to important parameter ranges (e.g. the NDVI values of plants) rather than the whole range.

\subsubsection{Effect of Dark Noise}
For the zero-noise, the 1m scenario had a calibrated RMSE of 0.12 compared to 0.26 in the 5m scenario (Standard Deviation $<0.001$). For increasing noise levels between 11 and 120 $e^-$, the calibrated RMSE increased in both scenarios, however the increase was greater in the high spatial resolution example, rising to 0.23 at 120$e^-$ . This was expected as the spatial degradation noise in the lower spatial resolution scenario already dominates. Even a completely noise-free example will have a RMSE $>1$ due to spatial downsampling kernel.

\begin{figure*}
%\includegraphics[width=\textwidth]{figures/test_output_calibration}
\caption{Uncalibrated (red points) and calibrated (black) simulated v. reference values with regression lines showing model fits. Panels show different noise levels}
\label{fig:cal}
\end{figure*}

\section{Conclusions}
\begin{enumerate}
\item The simulation pipeline generates linear simulations efficiently but needs a full code review. Other potential noise sources that have not been modelled should be considered and included if thought to be significant
\item The evaluation pipeline can be used to test different sensor parameters against spectral index retrieval performance. This will be developed further to score classification performance.
\item More information is needed for the likely ranges of sensor properties.
\end{enumerate}

\bibliography{references}

\end{document}
\documentclass[10pt,a4paper,final,onecolumn]{article}
%\usepackage{fontspec}
%\defaultfontfeatures{Mapping=tex-text}
%\usepackage{xunicode}
%\usepackage{xltxtra}
%\setmainfont{???}

\usepackage{amsmath}
\usepackage{amstext}
\usepackage{array}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}

\newcolumntype{L}{>{$}l<{$}} % math-mode version of "l" column type

\author{Fennell \textit{et al.}}
\title{High-level simulation of future multispectral imagery from the proposed TreeView satellite. v1.3}

\begin{document}
\maketitle
\begin{abstract}
This document describes the early work carried out for the development of a simulation-evaluation pipeline for earth orbit multispectral imagery. A description of the pipeline is presented and example outputs.
\end{abstract}
\section{Introduction}
% From proposal Docs
The TreeView project proposes a novel satellite solution for climate action that will drive a revolution in ‘Precision Forestry’ –- the use of advanced technologies for a more granular data capture and management. Forests are often considered large, remote areas that require low maintenance during their lifetime and can be managed in homogeneous units called forest stands. But new political, environmental, social and commercial drivers necessitate a more diverse approach of mixed species and smaller scale planting. Individual trees are the fundamental unit of these resources, and the target of TreeView. 

\subsection{Work Package 2000: Science Requirements}
Current work (Q4 2020) focuses on the need to constrain the engineering design with understanding of the likely measurements that will be made with the proposed system. In order to do this, both a simulation methodology and a set of relevant performance metrics must be adopted, such that different combinations of band-pass filter and sensor characteristics can be evaluated for different geographically-relevant atmospheric conditions.

In designing the work the following considerations were made:

\begin{enumerate}
\item As this project relates specifically to the measurement of single trees (as opposed to forest stands), tree stands and individual isolated trees of various sizes will both be considered when designing performance metric experiments
\item Due to the limited knowledge of the likely system architectures at this stage in the development process, a high-level approach will be taken to simulation of synthetic images with assumptions made about the likely distributions and properties of noise at different stages in the simulation.
\item The range of possible spectral sensitivities will be limited to what is feasible with a silicon detector, and observable through standard glass optics ($\lambda \approx 400 - 900$ nm).
\item The simulation pipeline is designed using Dask/Python as it is (i) Open Source (and so easily verified, reviewed and tested by any research group) and (ii) a natively parallel environment for efficient, scalable computation.
\end{enumerate}
 
\subsection{Simulation of a line-scanning sensor}
A line-scanning Time Delay Integration (TDI) Charged Metal Oxide Silicon (CMOS) sensor is the only likely sensor suitable for purpose and so this work focuses on the simulation only of this class of sensor.

\section{Methods}
This section details the tools and methodologies used for each stage in the simulation/evaluation pipeline.
\subsection{Imagery Collection}
Hyperspectral aerial imagery from the project partners 2ExcelGeo have been used as the main reference data for these simulations. The relevant datasets from the aerial collect were the HySpex VNIR covering a spectral range covering the 400-900 nm band and at a ground sampling distance of $0.33 m pixel^{-1}$ - much higher spatial and spectral resolution than the proposed mission. Imagery have been collected over a number of UK cities including Milton Keynes and Birmingham. Time sequences (multiple images of the same ground area) have been collected over some areas and will be made available to this team within the current project.

The measured at-sensor radiance is converted to a reflectance value through an  atmospheric correction model implemented in ENVI software (QUAC [ref needed]). This is carried out by the data providers (2ExcelGeo). The QUAC method is based on the use of lookup tables of pure endmember reflectances and their corresponding radiance under known solar conditions. The ill-posed problem is then treated as a spectral-unmixing of known endmembers. It is favoured for it's low computation demand, however there is some concern that the approach may introduce spectral artefacts to the imagery that are hard to quantify and studies have shown worse performance than conventional radiative transfer model inversion methods such as FLAASH [citation needed]. More work needed to understand if a more rigorous atmospheric approach is needed for these data.

\subsection{Simulation}
\subsubsection{Definitions}
\begin{tabular}{Ll}
\toprule
Symbol & Definition \\ 
\midrule
A_{pix} & Area of pixel \\
a_{fov} & Angular Field of View\\
CONU & Column Offset Non-Uniformity \\
d_{swath} & Swath width\\
d_{altitude} & Altitude of sensor\\
D & Diameter of front optic \\
DN & Digital Number \\
DSNU & Dark Signal Non-Uniformity \\
FWHM & Full Width at Half Maximum\\
FWC & Full Well Capacity\\
f & Focal length\\
g(x^{\prime}, y^{\prime}) & Spatial degradation kernel function \\
G_{ADC} & ADC Gain \\
G_{SN} & Sense node gain \\
hc & $1.98644586\times 10^{-25}$\\
k_{dark} & coefficient of non-uniformity in dark signal \\
k_{light} & coefficient of non-uniformity in photon response \\
k_{offset} & coefficient of column amplifier non-uniformity \\
\lambda & Wavelength ($nm$)\\
\Lambda & Poisson parameter \\
L_{e, \Omega} & Radiant Energy ($W m^{-2} sr^{-1}$)\\
L_{\Omega} & Radiant Photon flux ($m^{-2} sr^{-1} s^{-1}$)\\
\nu_{y} & Line read frequency\\
\bar{N}_{p}  & Mean photons per pixel per cycle \\
\Omega & Solid angle\\
PRNU & Photon Response Non-Uniformity \\
R(\lambda) & Spectral reflectance\\
sr & Steradian \\
s\prime & Rear optic-sensor separation \\
\sigma & Standard deviation \\
t_{eff} & effective integration time \\
T(\lambda) & Spectral transmittance \\
V_s & CMOS sensor voltage \\
V_{ADC} & ADC reference voltage \\
V_{SN} & CMOS reference voltage \\



 
\bottomrule
\end{tabular} 
\subsubsection{Reflectance to at-sensor radiance}
In broad terms, the purpose of the atmospheric simulation is to map from ground reflectance ($R$) to an at-sensor radiance ($L_{e, \Omega}$):

\begin{equation}
R(\lambda) \rightarrow L_{e, \Omega} (\lambda)
\end{equation}

Established radiative transfer modelling approaches were used in the simulation. Primarily, the 6SV [ref needed] code from NASA was used to convert the measured ground reflectance to at-sensor radiance outside the atmosphere. The code is considered a medium-complexity, line-by-line approach and is used for atmospheric correction of MODIS data. For practical implementation reasons, the 6SV code (a FORTRAN library accessed via the Py6S bindings) has been used to generate Lookup Tables (LUTs) for a limited range of parameter values.

In the first stages, the following approximations are proposed:
\begin{enumerate}
\item The satellite observes each pixel in space, at nadir. If the centre of the image plane is assumed to be directly beneath the satellite's orbital path, then the inaccuracy introduced by this approximation increases towards the edges of the image plane. This is a reasonable approximation for a narrow field-of-view, high resolution device as proposed. 
\item The atmospheric optical thickness will be set at a range typical of the UK. All test data is of UK locations and the UK's climatic conditions are quite challenging for optical imaging. This is therefore a useful starting point for simulation.
\item All individual pixels in the imagery array will be considered as independent homogeneous lambertian diffusers for the purpose of the 6SV simulation. As such, the spatial response function is handled at a later stage in the pipeline.
\item The simulation is evaluated for all wavelengths between 
\end{enumerate}

\subsubsection{Radiant energy to radiant quanta}
The top-of-atmosphere apparent radiance is converted from energy ($L_{e,\Omega}$) to quantity of photons ($L_{\Omega}$) using the Planck-Einstein relation:
\begin{equation}
L_{\Omega}(\lambda) = L_{e,\Omega}(\lambda)\frac{\lambda}{hc}
\end{equation}

\subsubsection{Application of bandpass response functions}
For every band, the bandpass transmittance is multiplied element-wise by the radiant flux and integrated w.r.t. wavelength
\begin{equation}
L_{\Omega}(band)= \int_{400}^{900}(L_{\Omega}(\lambda)T_i(\lambda))~d\lambda
\end{equation}

where $T_{band}$ is the transmission spectrum of a bandpass filter

\subsubsection{Spatial resampling}
The spatial response function takes into account atmospheric blurring, optical imperfections, motion blur, etc. of the entire system.

To convert from the ground plane to image plane, the integrated radiant flux ($L_{\Omega}(band)$) are separately convolved with the spatial response function, $g(x^\prime,y^\prime)$.
\begin{equation}
L_{\Omega}(band, x, y) = g(x^\prime, y^\prime) * L_{\Omega}(band, x^\prime, y^\prime)
\end{equation}
where $x, y$ are simulated sensor spatial position indices and $x^{\prime}, y^{\prime}$ are input array position indices.

In the absence of more information about the optical properties, the spatial response function ($g(x^\prime, y^\prime)$) has been approximated as a 2D gaussian with parameters derived empirically. An example of this using the Sentinel 2 Point Spread Function estimated the 10m ground sampling distance Sentinel 2 bands to have a Full Width at Half Maximum (FWHM) of 22.08 m and this ratio was used for preliminary estimates of different ground sampling distances.

The FWHM is converted to pixel-plane sigma:

\begin{equation}
\sigma_{xy} = \frac{(FWHM/2.355)}{dx}
\end{equation}

where $dx = dy$

and used to generate the gaussian kernel:

\begin{equation}
g(x^\prime, y^\prime) =\exp \left[-\left({\frac {(x^\prime-x_{0}^\prime)^{2}}{2\sigma _{xy}^{2}}}+{\frac {(y^\prime-y^\prime_{0})^{2}}{2\sigma _{xy}^{2}}}\right)\right]
\end{equation}

After convolution, the new array is then resampled by taking the local mean over a subset of cells representing the area of one sensor pixel.

\subsubsection{Radiance to sensor flux density}
The at-satellite radiance ($L_{\Omega}(band)$) is in units of photons per steradian per ground area per second ($sr^{-1} m^{-2} s^{-1}$) and so requires conversion to at-sensor flux density ($E$) ($m^{-2} s^{-1}$). When treated as a thin lens problem (in the absence of optic specifics) the irradiance at a position($\textbf{x}$) on the sensor is calculated as the solid angle subtended by the lens. We follow the interpretation by \cite{Sato1999} to show that sensor irradiance is linearly related to radiance and dependent on the diameter of the front optic ($D$), focal length ($f$) and the pixel-lens normal offset angle ($\alpha$):
\begin{equation}
E(band, x, y) = L_{\Omega}(band) \frac{\pi}{4} \left(\frac{D}{f}\right)^{2} \cos^4 \alpha(x,y)
\label{eqn1}
\end{equation}

The angular field of view ($a_{fov}$) is calculated from the swath width ($d_{swath}$) and sensor altitude ($d_{altitude}$):

\begin{equation}
a_{fov} = 2\cdot \tan^{-1}\frac{0.5\cdot~d_{swath}}{d_{altitude}}
\end{equation}

The focal length ($f$) is calculated assuming the optic will be focused near infinity and so, from the thin lens equation, the distance between rear optic and lens ($s\prime$) is approximately equal:

\begin{equation}
\frac{1}{s^\prime} + \frac{1}{\infty} = \frac{1}{f} \approx \frac{1}{s^\prime}
\end{equation}

and so the angular field of view ($a_{fov}$) and sensor width ($d_{sensor}$) are used to calculate the required focal length:

\begin{equation}
f= \frac{d_{sensor}}{\tan a_{fov}}
\end{equation}

As focal length is expected to be very large due to the distance from target and narrow swath needed to achieve target ground sampling distances, the $\cos^4\alpha(x, y)$ term will have a minimal effect on the simulation and so is omitted for computational simplicity

\subsubsection{Effective Integration Time}
The Time Delay Integration sensor uses a column of pixels to collect photons from the same point in space as the sensor passes over. This increases the effective integration time ($t_{eff}$), calculated from the line rate ($\nu_{y}$) and the number of rows in a TDI pixel sub-array ($n$).

\begin{equation}
t_{eff} = \frac{n}{\nu_{y}}
\end{equation}

\subsubsection{Flux density to pixel quantity}
To convert from pixel flux density ($E$) to pixel photon count:

\begin{equation}
\bar{N}_{p}(x, y, band) =  E(band, x, y) t_{eff} A_{pix}
\end{equation}

where $t_{eff}$ is integration time and $A_{pix}$ is the area of the pixel. The quantity $\bar{N}_{p} $  describes the mean number of photons striking a pixel in any given integration cycle.

\subsubsection{Photon shot noise}
The photon count at the sensor can be expressed as a Poisson process such that the $\Lambda$ coefficient of each process is the observed count for a given pixel

\begin{equation}
N_{p}(x, y, band) \sim Poisson(\Lambda)
\end{equation}

Where the estimated photon quantity at each pixel, $\bar{N}_{p}(x, y, band) $ is the $\Lambda$ coefficient for each distribution.

\subsubsection{Photon to electron}
To convert from photon to electron, given a known sensor quantum efficiency:

\begin{equation}
N_{light}=  round(N_{p}(x, y, band) \cdot \bar{Q}_{E,band})
\end{equation}

where $\bar{Q}_{E,band}$ is the weighted mean of the quantum efficiency in each band:

\begin{equation}
\bar{Q}_{E, band} = \sum_{\lambda=300}^{900} Q_{E}(\lambda) \left(\frac{T_{band}(\lambda)}{\int_{300}^{700} T_{band}(\lambda) d\lambda}\right)
\end{equation}

\subsubsection{Photon Response Non-Uniformity}
The response of the sensor varies from pixel to pixel and so this non-uniformity can be treated as a zero mean gaussian distribution (i.e. the mean effect over the whole sensor is zero)

\begin{equation}
PRNU \sim \mathcal{N}(0, \sigma_{PRNU}^{2})
\end{equation}

where

\begin{equation}
\sigma_{PRNU} = k_{light}
\end{equation}
 where $k_{light}$ is the coefficient of photon response non-uniformity provided by the manufacturer.
 
\subsubsection{Dark current estimation}
The dark current density ($j_{dark}$) is measured at a constant temperature ($20^{\circ} C$) and so the mean signal per sub-pixel array is estimated as

\begin{equation}
\bar{N}_{dark} = 6.242 \times 10^{18} \cdot j_{dark} \cdot t_{eff} \cdot A_{pix}
\end{equation}

\subsubsection{Dark Signal Non-Uniformity}
The dark signal will vary pixel to pixel and so this is accounted for with a zero-mean log-gaussian distribution (i.e. the mean effect over the whole sensor is zero). This has been experimentally shown to be suitable of integration times of less than 100 seconds

\begin{equation}
DSNU \sim Log\mathcal{N}(0, \sigma_{DSNU}^{2})
\end{equation}

where

\begin{equation}
\sigma_{DSNU} = \bar{N}_{dark} \cdot t_{eff} \cdot k_{dark}
\end{equation}

where $k_{dark}$ is the coefficient of non-uniformity, provided by the manufacturer.

\subsubsection{Dark current shot noise}
The dark current is expected to follow a Poisson distribution and so 

\begin{equation}
N_{dark}(x, y, band) \sim Poisson(\Lambda)
\end{equation}

Where the estimated photon quantity at each pixel, $\bar{N}_{dark}(x, y, band) $ is the $\Lambda$ coefficient for each distribution.

\subsubsection{Read Noise}
The read noise is estimated from measured values and is assumed independent of signal. It is modelled as a zero-mean gaussian

\begin{equation}
N_{read} \sim \mathcal{N}(0, \sigma_{read}^{2})
\end{equation}

\subsubsection{Total charge}
The signals are added
\begin{equation}
N = N_{dark} + (N_{dark} \cdot DSNU) + N_{light}
+ (N_{light} \cdot PRNU) + N_{read}
\end{equation}

This value is truncated at the full well capacity of the pixel sub-array.


\subsubsection{Charge to voltage}
The charge collected during an integration cycle is then converted to a voltage by the column amplifiers

\begin{equation}
V_s = V_{SN}(N \cdot G_{SN})
\end{equation}
where $V_{SN}$  is the reference voltage (V) and $G_{SN}$ is the sense node gain ($V/e^{-}$).

The Full Well Capacity ($FWC$) can be used to define $G_{SN}$ to cover the full charge handling capacity of the sensor:

\begin{equation}
G_{SN} = \frac{V_{SN}}{FWC}
\end{equation}

\subsubsection{Conversion to Digital Number}
The amplified voltage is then converted to a digital number (DN) the Analogue-Digital Converter (ADC)

\begin{equation}
DN = DN_{max}~\frac{V_s}{V_{ADC}}
\end{equation}
where $V_{ADC}$  is the Analogue-Digital Converter reference voltage.

The resulting array is truncated between zero and the maximum DN value ($DN_{max}$) to simulate non-detection and clipping behaviours.

\subsubsection{Conversion to reflectance}
For testing and evaluation purposes, the pipeline is used to generate a sensor response for a 100\% reference image (i.e. all atmospheric and sensor parameters are known \textit{a priori}). The image signal is then divided by reference signal to produce the estimate of reflectance at surface level.

\begin{equation}
\widehat{R}(\lambda)= \frac{DN}{DN_{100}}
\end{equation}

Noisy reference spectra can easily be generated by replacing fixed parameters with a distribution from which instances are sampled, for example to explore effect of uncertainties in Atmospheric Optical Thickness (AOT) measurement.

\section{Evaluating Performance}
Performance metrics for a given sensor-atmosphere parametrisation can be divided into classification and parameter estimation metrics

\subsection{Parameter estimation}
A spectral index (defined by narrowband wavelength or wavelength ranges) is first estimated from the hyperspectral data and is used as the reference value. An analagous definition for the sensor is then separately defined.

For example for Normalised Difference Vegetation Index (NDVI):

\begin{equation}
S = \frac{R_{infrared} - R_{red}}{R_{infrared} + _{red}}
\end{equation}

where $R$ can be defined differently for each sensor.

\begin{equation}
RMSE = \sqrt{\frac{(S_{ref}-S_{sim})^{2}}{N}}
\end{equation}


\section{Scenario Modelling}

\subsection{Atmospheric Conditions}
Atmospheric Conditions were selected for two UK cities at different latitudes (Table \ref{tab:atmos1}): Milton Keynes (mk) and Inverness (inv) to reflect the range of latitudes to which the mission is targeted. Five dates were selected from 1st March through to 1st of October to reflect the biologically significant period of observation.

\begin{table}[]
    \centering
    \include{tables/1_atmospheric}
    \caption{Input parameters for different UK atmospheric simulations. All other parameters were fixed for all scenarios (AOT: 0.5, view Z: 0, view A: 0) with the exception of the atmospheric model which was selected automatically by Py6SV according to the position and date}
    \label{tab:atmos1}
\end{table}

\subsection{Dynamic Range Estimation}
Reflectance imagery collected by an aerial platform was used for dynamic range estimation. A small subset was selected to contain a range of vegetation types (mown grass and mature deciduous trees) and other landcovers including tarmac roads, bare earth and domestic structures. As expected, vegetation had low reflectance in human visible wavelengths (<5\%) with higher reflectances in the Near Infra Red (Figure \ref{fig:reflectances1}).
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{TreeView_plots/1_input_reflectance.png}
    \caption{Reflectance estimates of a scene over Milton Keynes at 442nm, 554nm, 698nm, 842nm. Colourscale is in log units}
    \label{fig:reflectances1}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{TreeView_plots/2_input_reflectance_histogram.png}
    \caption{2D Histogram of reflectances per waveband for the scene in Figure \ref{fig:reflectances1}}
    \label{fig:reflectances_hist}
\end{figure}

Reflectances values were 

\section{Conclusions}
\begin{enumerate}
\item The simulation pipeline generates linear simulations efficiently but needs a full code review. Other potential noise sources that have not been modelled should be considered and included if thought to be significant
\item The evaluation pipeline can be used to test different sensor parameters against spectral index retrieval performance. This will be developed further to score classification performance.
\item More information is needed for the likely ranges of sensor properties.
\end{enumerate}

\bibliography{references}

\end{document}